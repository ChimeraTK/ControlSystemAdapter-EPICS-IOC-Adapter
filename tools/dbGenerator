#!/usr/bin/python3

"""
Tool to generate EPICS PV database, autosave requirement file and documentation for PV database
from a configuration xml-file and various other sources
Written and tested for Python 3.5.2 @ June 2019 by Patrick Nonn for DESY/MSK
"""

import argparse  # Parse command line arguments
import os  # For file manipulation
import sys
import xml.etree.ElementTree as xmlEleTree  # xml parser
from typing import List, Any

VERSION = '0.1'

'''
Changelog:

Unreleased:
    Parsing of xml-files and extracting information for mapping
'''


# Class to build structs
class Struct:
    pass


# Class for text formatting
class AsciiFormat:
    warning = '\033[1m\033[93mWarning:\033[0m '
    error = '\033[1m\033[91mError:\033[0m '

    @staticmethod
    def bold(text):
        return '\033[1m' + text + '\033[0m'


# Define Exception
class XmlNodeError(Exception):
    """Exception raised, if xml-node invalid"""

    def __init__(self, xpath, message):
        self.xPath = xpath
        self.Message = message


class Table:
    """Container class for structured data in table format. Data added in rows, but can be accessed by column name."""

    # Constructor
    def __init__(self, column_names, content_list=None):
        if not isinstance(column_names, (list, str)):  # Check for right attribute type
            raise TypeError('The first attribute of table() has to be of type list or string!')
        if isinstance(column_names, str):  # Conversion to list type if it is string
            column_names = [column_names]
        elif not all(map(lambda x: isinstance(x, str), column_names)):  # Check for list content being string
            raise TypeError('The first attribute of table() has to be a list of strings!')
        elif len(column_names) != len(set(column_names)):  # Check for duplicates
            raise AttributeError('The first attribute of table() can\'t contain duplicates!')
        else:
            self._head = column_names
        if content_list is not None:  # Process content given at initialization
            if not all(map(lambda x: isinstance(x, (list, dict)), content_list)):  # Check types
                raise TypeError('The second attribute of table() has to be None or a list of lists or dictionaries!')
            if any(map(lambda x: len(x) < len(column_names), content_list)):  # Check lengths of items
                raise AttributeError('The second attribute of table() has to be a list of lists or dictionaries, '
                                     'which are of the same length, as the first attribute!')
            if all(map(lambda x: isinstance(x, list), content_list)):  # Process list of lists
                for row in content_list:
                    # Check, if row has the required length
                    if len(row) != len(self._head):
                        sys.stderr.write('At least one list has not the right length!')
                    else:
                        # Convert list of uniform lists to list of uniform dictionaries
                        self.add(dict(zip(self._head, row)))
            elif all(map(lambda x: isinstance(x, list), content_list)):  # Process list of lists
                self._table = content_list
            else:  # Something is very wrong, if we get here
                raise AttributeError('The second attribute, if not None, has to be a list of ONLY lists or a list of '
                                     'ONLY dictionaries!')
        else:
            self._table = []

    # Representation of table object
    def __repr__(self):
        return 'Table object with ' + str(len(self._table)) + ' entries.'

    # Printed output of table object
    def __str__(self):
        output = ['\033[1m' + str(self._head) + '\033[0m']
        for table_row in self._table:
            output.append(list(table_row.values()))
        return '\n'.join(output)

    # Magic method for "object['columnName']" accessor. Returns list of named columns content.
    def __getitem__(self, col):
        if col in self._head:
            output = []  # type: List[Any]
            for table_row in self._table:
                output.append(table_row[col])
            return output
        else:
            raise AttributeError('table has no column named "' + str(col) + '"')

    # Magic method for len()-function, returns number of "rows"
    def __len__(self):
        return len(self._table)

    # Magic method to initialize iterator.
    def __iter__(self):
        self._index = 0
        self._row = None
        return self

    # Magic method to increment iterator.
    def __next__(self):
        if self._index > len(self._table) - 1:
            del self._index
            del self._row
            raise StopIteration
        else:
            self._row = self._table[self._index]
            output = self._row
            self._index = self._index + 1
            return output

    # Method to add "row".
    def add(self, row):
        if not isinstance(row, dict):  # Check Type
            raise TypeError('table.add() expects a dictionary as argument')
        if len(row) < len(self._head):  # Check length
            raise ValueError('The argument of add_row has to be a dictionary with the length of at least '
                             + str(len(self._head)))
        if any(map(lambda col:
                   all(map(lambda key:
                           col != key, list(row.keys()))),
                   self._head)):  # Check keys
            raise AttributeError('The dictionary given to table.add() misses at least one key, defined in the first '
                                 'attribute of table()!')
        self._table.append(row)

    # Method to search for "row(s)" containing defined pattern, which can be a dict or a string.
    def query(self, pattern):
        result = []
        if not isinstance(pattern, (dict, str)):
            raise TypeError('table.query() takes a dict or a string as argument!')
        elif isinstance(pattern, dict):
            result += self._table
            for pattern_key in pattern:
                if pattern_key in self._head:
                    result = list(filter(lambda x: x[pattern_key] == pattern[pattern_key], result))
        elif isinstance(pattern, str):
            for head_key in self._head:
                result += list(filter(lambda x: x[head_key] == pattern, self._table))
        return result


class PVDb(Table):
    """Main container for data from all sources"""

    def __init__(self):
        super().__init__(['ID', 'pvName', 'autosave', 'doku', 'fields'], None)
        self._aliases = {}

    # Magic method for "object['columnName']" accessor. Returns list of named columns content.
    def __getitem__(self, pv_id):
        if not isinstance(pv_id, str):  # Check Type
            raise TypeError('Attribute of PVDb[] has to be string.')
        query_result = super().query({'ID': pv_id})  # Find Entry
        if len(query_result) == 0:  # Check existence
            sys.stderr.write('PV with ID ' +
                             pv_id +
                             ' does not exist in PVDb')
        elif len(query_result) == 1:  # Usual case
            index = self._table.index(query_result[0])
            return self._table[index]
        elif len(query_result) >= 1:  # Check Multiple Entries
            sys.stderr.write('Multipe PVs with ID ' +
                             pv_id +
                             ' found in PVDb! PVDb might be corrupted!')
        else:  # For unforeseen cases
            raise RuntimeError('Something has gone wrong!')

    # Method to add rows to database
    def add(self, row):
        if not isinstance(row, dict):  # Check Type
            raise TypeError('PVDb.add() expects a dictionary as argument')
        if len(row) < len(self._head):  # Check Length
            raise ValueError('The argument of add_row has to be a dictionary with the length of at least '
                             + str(len(self._head)))
        if any(map(lambda col:
                   all(map(lambda key:
                           col != key, list(row.keys()))),
                   self._head)):  # Check Keys
            raise AttributeError('The attribute of PVDb.add() misses at least one of the following keys:\n' +
                                 str(self._head))
        super().add(row)

    def _expand(self, in_str):
        if isinstance(in_str, str):
            pos_open = in_str.find("{")
            if pos_open != -1:
                pos_close = in_str.find("}", pos_open + 1)
                if pos_close == -1:
                    return in_str
            else:
                return in_str
            try:
                if pos_close - pos_open > 1:  # Check for empty curly brackets
                    macro = self._aliases[in_str[pos_open + 1:pos_close]]
                else:
                    sys.stderr.write(AsciiFormat.warning +
                                     'Empty Macro in string "' +
                                     in_str +
                                     '" will be ignored!\n')
                    macro = ''
            except KeyError:
                sys.stderr.write(AsciiFormat.warning +
                                 'Macro ' +
                                 in_str[pos_open:pos_close + 1] +
                                 ' not defined, and will be ignored!\n')
                macro = ''
            out = self._expand(in_str[:pos_open] + macro + in_str[pos_close + 1:])
        else:
            raise TypeError('The _expand method of ' + self.__name__)
        return out


def expand_alias(in_string, alias_dict):
    """Function to expand aliases"""

    pos_open = in_string.find("{")
    if pos_open != -1:
        pos_close = in_string.find("}", pos_open + 1)
        if pos_close == -1:
            return in_string
    else:
        return in_string
    macro = alias_dict[in_string[pos_open + 1:pos_close]]
    temp = in_string[:pos_open] + macro + in_string[pos_close + 1:]
    out = expand_alias(temp, alias_dict)
    return out


def make_index(xml_node, ns_prefix, ns_dict, pv_path=''):
    """
    Recursive function to iterate through the xml tree and isolate the 'variables'
    while maintaining the path in order to generate an index.
    Takes:
        xml_node: xml handle to start the recursion
        ns_prefix: Namespace prefix (without ':')
        ns_dict: Namespace dictionary, containing nsPrefix
        pv_path: Path to the node, from which the function is called.
    Returns:
        index: dictionary, holding xpath and handle for the corresponding 'variable'-node
    """
    index = {}
    for v in xml_node.findall(ns_prefix + ':variable', ns_dict):
        index[pv_path + v.get('name')] = v
    for d in xml_node.findall(ns_prefix + ':directory', ns_dict):
        index.update(make_index(d, ns_prefix, ns_dict, pv_path=pv_path + d.get('name') + '/'))
    return index


def process_xml_variable(source_handle):
    """
    Processes source file, defined in 'sourcefile' tag, with type 'xml-variables'.
    Returns table holding the content of sourcefile.
    """
    if source_handle.get("type") != "xml-variables":
        raise XmlNodeError(source_handle.tag, 'sourcefile is not defined as type = xml-variables.')
    # Dictionary to convert c types into EPICS counterparts
    type_conversion = {'int64': 'INT64',
                       'uint64': 'UINT64',
                       'int32': 'LONG',
                       'uint32': 'ULONG',
                       'int16': 'SHORT',
                       'uint16': 'USHORT',
                       'int8': 'CHAR',
                       'uint8': 'UCHAR',
                       'double': 'DOUBLE',
                       'float': 'FLOAT',
                       'string': 'STRING'}
    # Dictionary to convert "direction" to EPICS IN/OUT
    direction = {'control_system_to_application': 'OUTPUT',
                 'control_system_to_application_with_return': 'OUTPUT',
                 'application_to_control_system': 'INPUT',
                 'application_to_control_system_with_return': 'INPUT'}
    # Initialize output table
    out = Table(['VariablePath', 'ValueType', 'NumberOfElements', 'Direction', 'Unit', 'Description'])
    # Getting xml parsing essentials
    label = source_handle.get("label")
    tree = xmlEleTree.parse(source_handle.get("path"))
    root = tree.getroot()
    namespace = {label: source_handle.get("namespace")}
    # Indexing "variables" in xml file
    index = make_index(root, label, namespace)
    # Extract Information from source xml
    for variable in index.items():
        # Error Management
        var_path = variable[0]
        type_str = ''
        try:
            type_str = variable[1].find(label + ':value_type', namespace).text
            v_type = type_conversion[type_str]
        except KeyError:
            sys.stderr.write('Value type "' +
                             type_str +
                             '" is not known!')
            v_type = None
        except AttributeError:
            sys.stderr.write('Attribute "value_type" not found in ' +
                             AsciiFormat.bold(var_path))
            v_type = None
        try:
            var_direction = direction[variable[1].find(label + ':direction', namespace).text]
        except AttributeError:
            sys.stderr.write('Attribute "direction" not found in ' +
                             AsciiFormat.bold(var_path))
            var_direction = None
        try:
            var_unit = variable[1].find(label + ':unit', namespace).text
        except AttributeError:
            sys.stderr.write('Attribute "unit" not found in ' +
                             AsciiFormat.bold(var_path))
            var_unit = ''
        out.add({
            'VariablePath': var_path,
            'ValueType': v_type,
            'Direction': var_direction,
            'Unit': var_unit,
            'Description': variable[1].find(label + ':description', namespace).text,
            'NumberOfElements': int(variable[1].find(label + ':numberOfElements', namespace).text)})
    return out


def find_x_dir(xml_root, ns_prefix, ns_dict, xpath):
    """
    Returns address of directory-node, described in xPath.
    """
    nodes = [xml_root]
    for xml_node in xpath.split('/'):
        temp = nodes[-1].findall(ns_prefix + ":directory[@name='" + xml_node + "']", ns_dict)
        if len(temp) == 0:
            raise XmlNodeError(xpath, 'findXDir: "directory" node does not exist!')
        elif len(temp) > 1:
            sys.stderr.write(
                AsciiFormat.warning +
                'Multiple directory-nodes named ' +
                xml_node +
                ' found. First one will be used!\n')
        else:
            nodes.append(temp[0])
    return nodes[-1]


def xml_tag_description(xml_node):
    """Returns string describing content of node"""
    node_type = xml_node.tag.split('}')[-1]
    if node_type == 'outputfile':
        output = AsciiFormat.bold('outputfile') + ' for ' + AsciiFormat.bold(node.get('path'))
    elif node_type == 'recordgroup':
        output = AsciiFormat.bold('recordgroup') + ' of type ' + AsciiFormat.bold(node.get('type'))
    elif node_type == 'pv':
        output = AsciiFormat.bold('pv') + ' named ' + AsciiFormat.bold(node.get('pvName'))
    else:
        output = AsciiFormat.bold('unknown')
    return output


def get_macro(xml_node, ns_prefix, ns_dict):
    """
    Returns a struct holding length and placeholder as defined in the FIRST "macro" tag
    under the xml.etree Element, given in "node"
    "nsDict" is a dict holding "nsPrefix" and namespace(s) as key:value pairs.
    """
    output = Struct()  # type: Struct
    output.node = xml_node.find(ns_prefix + ':macro', ns_dict)
    whoami = xml_tag_description(xml_node)  # For error messages
    if output.node is None:  # There is no 'macro' child in this xml element
        output.length = 0
        output.placeholder = ''
    else:
        temp_length = output.node.get('length')
        temp_ph = output.node.get('placeholder')
        if temp_length is None:  # "macro"-child exists, but has no "length"-attribute
            sys.stderr.write(AsciiFormat.error +
                             'No "length" was defined for macro in' +
                             whoami +
                             '! PV name(s) will have no macro.\n')
            output.length = 0
            output.placeholder = ''
        else:
            output.length = int(temp_length)
        if temp_ph is None:  # "macro"-child exists, but has no "placeholder"-attribute
            sys.stderr.write(AsciiFormat.error +
                             'No "placeholder" was defined for macro in' +
                             whoami +
                             '! PV name(s) will have no macro.\n')
            output.length = 0
            output.placeholder = ''
        else:  # Everything is as expected
            output.placeholder = str(output.node.get('placeholder'))
    return output


def get_autosave(xml_node, ns_prefix, ns_dict):
    """
    Returns a boolean as defined in the FIRST "autosave" tag under the xml.etree Element, given in "node".
    "nsDict" is a dict holding "nsPrefix" and namespace(s) as key:value pairs.
    """
    output = Struct()  # type: Struct
    output.node = xml_node.find(ns_prefix + ':autosave', ns_dict)
    whoami = xml_tag_description(xml_node)  # For error messages
    if output.node is None:  # There is no 'autosave' child in this xml element
        output.active = None
    elif output.node.get('isActive') is None:  # autosave child exists, but has no "isActive"-attribute
        sys.stderr.write(AsciiFormat.error +
                         'No "isActive" was defined for autosave in' +
                         whoami +
                         '! PV will not be added to autosave.\n')
        output.active = None
    elif output.node.get('isActive').lower() not in ['true', 'false']:  # "isActive"-attribute holds unrecognized value
        sys.stderr.write(AsciiFormat.error +
                         '"isActive", defined for autosave in' +
                         whoami +
                         ' has to be "true" or "false" (not case-sensitive), but is not! '
                         'PV will not be added to autosave.\n')
        output.active = None
    else:  # Everything is as expected
        output.active = {'true': True, 'false': False}[output.node.get('isActive').lower()]
    return output.active


def get_fields(xml_node, ns_prefix, ns_dict):
    """
    Returns a dictionary holding all "field" tags type:value attributes under the xml.etree Element,
     given in "xml_node" as key:value pairs.
    "ns-dict" is a dict holding "ns-prefix" and namespace(s) as key:value pairs.
    """
    output = dict()
    field_nodes = xml_node.findall(ns_prefix + ':field', ns_dict)
    whoami = xml_tag_description(xml_node)  # For error messages
    for field in field_nodes:
        field_type = field.get('type')
        field_value = field.get('value')
        if field_type is None:
            if field_value is None:
                sys.stderr.write(AsciiFormat.error +
                                 'No "value" attribute was defined for a "field" child in' +
                                 whoami +
                                 '! "field" element will be ignored! \n')
            sys.stderr.write(AsciiFormat.error +
                             'No "type" attribute was defined for a "field" child in' +
                             whoami +
                             '! "field" element will be ignored! \n')
        elif field_value is None:
            sys.stderr.write(AsciiFormat.error +
                             'No "value" attribute was defined for a "field" child in' +
                             whoami +
                             '! "field" element will be ignored! \n')
        else:
            output[field_type] = field_value  # Fields of the same type overwrite!
    return output


CLAP = argparse.ArgumentParser(
    description='Generates EPICS PV database for every \'PV\' defined in ChimeraTK-xml file to EPICS database file.')
CLAP.add_argument('-c', help='Path to configuration file. Defaults to "mapConfig.xml"', metavar='path')
CLAP.add_argument('-v', help='Activates verbosity', action='store_true')
# Parse Command Line Arguments
CLA = CLAP.parse_args()

# Handle CLI arguments
# Handle default case
if CLA.c is None:
    inifile_path = os.getcwd()
    inifile_name = 'mapConfig.xml'
else:
    inifile_path, inifile_name = os.path.split(os.path.abspath(CLA.c))
    # Handle input of filename only
    if inifile_path is None:
        inifile_path = os.getcwd()
# Handle invalid/non-existing paths
if not os.path.isdir(inifile_path):
    sys.exit(AsciiFormat.error + 'Path ' + inifile_path + ' does not exist.')
elif not os.path.isfile(os.path.join(inifile_path, inifile_name)):
    sys.exit(AsciiFormat.error + 'File ' + inifile_name + ' does not exist.')

# Parse config file os.path.join(inifilePath, inifileName)
if CLA.v:
    print("Reading: " + os.path.join(inifile_path, inifile_name) + '\n')
cfgTree = xmlEleTree.parse(os.path.join(inifile_path, inifile_name))
cfgRoot = cfgTree.getroot()

# Define namespace
configNS = {'EPICSmap': 'https://github.com/ChimeraTK/ControlSystemAdapter-EPICS-IOC-Adapter'}
# Get a list of all sourcefile entries
sourcefiles = cfgRoot.findall("EPICSmap:sourcefile", configNS)

db = PVDb()
db.add({'ID': 'SYS/PV1',
        'pvName': 'PV-Name',
        'autosave': False,
        'doku': True,
        'fields': {'FIELD1': 'Val1', 'FIELD2': 'Val2'}})
db.add({'ID': 'SYS/PV2',
        'pvName': 'PV-Name2',
        'autosave': False,
        'doku': True,
        'fields': {'FIELD1': 'Val12', 'FIELD2': 'Val22'}})
print(str(db))
print(db['SYS/PV1'][4]['FIELD1'])

# Check existence of sourcefile element(s)
if len(sourcefiles) == 0:
    sys.stderr.write(AsciiFormat.warning + 'No source files are defined!\n')
else:
    if CLA.v:
        sourcelist = []
        for i in sourcefiles:
            sourcelist.append(os.path.abspath(i.get("path")))
        print('Found ' + str(len(sourcefiles)) + ' sources:\n- ' + '\n- '.join(sourcelist) + '\n')
    source = dict()
    alias = dict()
    for sfile in sourcefiles:
        # Check if sourcefile exists
        if not os.path.isfile(sfile.get("path")):
            sys.stderr.write(
                AsciiFormat.warning +
                "File \'" +
                os.path.abspath(sfile.get("path")) +
                "\' does not exist!\n")
        # Parse source file according to type
        sourceTag = sfile.get("label")
        if sfile.get("type") == "xml-variables":
            source[sourceTag] = process_xml_variable(sfile)
            # parse aliases
            for item in sfile.findall('EPICSmap:alias', configNS):
                alias[sourceTag + '.' + item.get('varLabel')] = item.get('xmlPath')
        else:
            sys.stderr.write(
                AsciiFormat.warning +
                'Source file type ' +
                sfile.get("type") +
                ' is unknown. Source file ' +
                sfile.get("path") +
                ' labeled ' +
                sfile.get("label") +
                ' will be ignored!\n')

# Get a list of all outputfile entries
outputFiles = cfgRoot.findall("EPICSmap:outputfile", configNS)
outputList = Table(['type', 'path', 'handle'])
for i in outputFiles:
    outputFile = {'path': os.path.abspath(i.get('path')), 'type': i.get('type'), 'handle': i}
    outputList.add(outputFile)
if CLA.v:
    print(str(len(outputList)) + ' output files are defined:\n' + str(outputList) + '\n')

for outFile in outputList:
    macro_rgroup = Struct()
    macro_rgroup.length = 0
    macro_rgroup.placeholder = ""
    autosave_rgroup = None
    fields_rgroup = dict()
    if outFile['type'] == 'db':
        node = outFile['handle']
        # process attributes for the whole file
        macro_file = get_macro(node, 'EPICSmap', configNS)
        autosave_file = {None: False, False: False, True: True}[get_autosave(node, 'EPICSmap', configNS)]
        fields_file = get_fields(node, 'EPICSmap', configNS)
        # process recordgroups
        rgroupList = node.findall('EPICSmap' + ':recordgroup', configNS)
        for rgroupNode in rgroupList:
            macro_temp = get_macro(rgroupNode, 'EPICSmap', configNS)
            if macro_temp.node is not None:
                macro_rgroup = macro_temp
            else:
                macro_rgroup = macro_file
            autosave_temp = get_autosave(rgroupNode, 'EPICSmap', configNS)
            if autosave_temp is not None:
                autosave_rgroup = autosave_temp
            else:
                autosave_rgroup = autosave_file
            fields_rgroup = fields_file
            fields_rgroup.update(get_fields(rgroupNode, 'EPICSmap', configNS))

        print(str(macro_rgroup.length) + '\t' + macro_rgroup.placeholder + '\n' + str(autosave_rgroup) + '\n' + str(
            fields_rgroup))

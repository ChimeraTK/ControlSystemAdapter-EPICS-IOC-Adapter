#!/usr/bin/python3

"""
Tool to generate EPICS PV database, autosave requirement file and documentation for PV database
from a configuration xml-file and various other sources
Written and tested for Python 3.5.2 @ June 2019 by Patrick Nonn for DESY/MSK
"""

import argparse  # Parse command line arguments
import os  # For file manipulation
import sys  # To access stdout and stdin
import xml.etree.ElementTree as xmlEleTree  # xml parser
from typing import List, Dict, Any, Union, Optional  # Type hints
from datetime import datetime  # To access system time

VERSION = '0.1'

'''
Changelog:

Unreleased:
    Parsing of xml-files and extracting information for mapping
'''


def abbreviate(in_word: str) -> str:
    """
    Function to abbreviate strings by look-up table.
    :param in_word: String
    :return: Abbreviation, if in_word is key in "abbr"-dictionary, in_word else.
    """
    if not isinstance(in_word, str):
        raise TypeError('The argument "input" of function "abbreviate" has to be of type string!')
    abbr = {
        'amplitude': 'amp',
        'average': 'avg',
        'calibration': 'cal',
        'configuration': 'config',
        'correction': 'corr',
        'deviation': 'dev',
        'filesystem': 'fs',
        'maximum': 'max',
        'minimum': 'min',
        'output': 'out',
        'processes': 'procs',
        'register': 'reg',
        'registers': 'regs',
        'request': 'req',
        'standard': 'std',
        'statistics': 'stats',
        'watchdog': 'wd'
    }
    try:
        output = abbr[in_word]
    except KeyError:
        output = in_word
    return output


# Class to build structs
class Struct:
    pass


# Class for text formatting
class AsciiFormat:
    warning = '\033[1m\033[93mWarning:\033[0m '
    error = '\033[1m\033[91mError:\033[0m '

    @staticmethod
    def bold(text):
        return '\033[1m' + text + '\033[0m'


# Define Exceptions
class XmlNodeError(Exception):
    """Exception raised, if xml-node invalid"""

    def __init__(self, xpath, message):
        self.xPath = xpath
        self.Message = message


class SkipLoop(Exception):
    """Exception raised, to skip a loop outside of the actual one"""

    def __init__(self, message):
        self.message = message
# End of Exception definitions


class Logging:
    """
    Class to handle logging
    depends on: os, sys, AsciiFormat
    """

    def __init__(self, logfile_path: str):
        """
        Constructor of class Logging.
        :param logfile_path: String holding filename of path to file to write log into.
        """
        if logfile_path is None or logfile_path == '' or os.path.isdir(logfile_path):  # Check plausability
            raise AttributeError('Class "Logging" initiated without defining path to logfile!')
        if not isinstance(logfile_path, str):  # Check Type
            raise TypeError('Class "Logging" was initiated with something different than a string!')
        if not os.path.isfile(logfile_path):  # Check, if file exists
            logfile_path_dir, logfile_path_filename = os.path.split(logfile_path)
            if logfile_path_dir == '':  # Check, if logfile_path is only filename
                self.logfile_path = os.path.abspath(logfile_path_filename)
            elif os.path.isdir(logfile_path_dir):  # Check, if directory, defined in logfile path, exists
                self.logfile_path = os.path.abspath(logfile_path)
            elif not os.path.isdir(logfile_path_dir):
                # If directory for logfile does not exist or is not accessible, use current working directory
                self.logfile_path = os.path.abspath(logfile_path_filename)
                sys.stderr.write('\033[1m\033[93mWarning:\033[0m: Directory defined for logfile is not accessible! '
                                 'Logfile will be generated in the current working directory.\n')
            else:
                raise AttributeError('Unrecognized Error, while processing Argument "logfile_path", '
                                     'passed to class "Logging"')
        else:  # logfile_path points to existing file
            self.logfile_path = os.path.abspath(logfile_path)
        with open(self.logfile_path, 'a') as f:
            f.write('--------------\n' + str(datetime.now()) + ': Beginning run of dbGenerator\n')

    def _markdown(self, in_str: str) -> str:
        """
        Recursive method to change strings containing ascii formatting for stdout to plain ascii.
        :param in_str: String to be changed
        :return: String without ascii formatting
        """
        if not isinstance(in_str, str):
            raise TypeError('_markdown takes only string type attributes')
        mark_left = '\033[1m'
        mark_left_len = len(mark_left)
        mark_right = '\033[0m'
        pos_open = in_str.find(mark_left)
        if pos_open != -1:
            if in_str.find('\33[9', pos_open + mark_left_len, pos_open + mark_left_len + 3) != -1:
                mark_left_len += len('\33[93m')
            pos_close = in_str.find(mark_right, pos_open + mark_left_len)
            if pos_close != -1:
                return self._markdown(in_str[:pos_open]
                                      + in_str[pos_open + mark_left_len:pos_close].upper()
                                      + in_str[pos_close + len(mark_right):])
            else:
                return in_str
        else:
            return in_str

    def write(self, log_message: str):
        """
        Method to write to log file and stderr
        :param log_message: String holding message to be written, formatted for stderr
        """
        if not isinstance(log_message, str):
            raise TypeError('Log takes only string type attributes')
        if log_message.find(AsciiFormat.warning) != -1:  # Check, if string contains warning tag
            sys.stderr.write(log_message + '\n')
            with open(self.logfile_path, 'a') as f:
                f.write(str(datetime.now()) +
                        ': ' +
                        self._markdown(log_message) +
                        '\n')
        elif log_message.find(AsciiFormat.error) != -1:  # Check, if string contains error tag
            sys.stderr.write(log_message + '\n')
            with open(self.logfile_path, 'a') as f:
                f.write(str(datetime.now()) +
                        ': ' +
                        self._markdown(log_message) +
                        '\n')
        else:  # When no tag is found
            sys.stdout.write(log_message + '\n')
            with open(self.logfile_path, 'a') as f:
                f.write(str(datetime.now()) +
                        ': ' +
                        self._markdown(log_message) +
                        '\n')


class Table:
    """Container class for structured data in table format. Data added in rows, but can be accessed by column name."""

    def __init__(self,
                 column_names: Union[str, List[str]],
                 content_list: Union[List[List[str]], List[Dict[str, Any]], None] = None):
        """
        Constructor of Table object

        :param column_names: List of strings, naming the columns of the table.
        :type column_names: list
        :param content_list: List containing either lists or dicts holding table content.
        :type content_list: list
        """
        if not isinstance(column_names, (list, str)):  # Check type
            raise TypeError('The first attribute of table() has to be of type list or string!')
        if isinstance(column_names, str):  # Conversion to list type if it is string
            column_names = [column_names]
        elif not all(map(lambda x: isinstance(x, str), column_names)):  # Check for list content being string
            raise TypeError('The first attribute of table() has to be a list of strings!')
        elif len(column_names) != len(set(column_names)):  # Check for duplicates
            raise AttributeError('The first attribute of table() can\'t contain duplicates!')
        else:
            self._head = column_names  # type: List[str]
        if content_list is not None:  # Process content given at initialization
            if not all(map(lambda x: isinstance(x, (list, dict)), content_list)):  # Check types
                raise TypeError('The second attribute of table() has to be None or a list of lists or dictionaries!')
            if any(map(lambda x: len(x) < len(column_names), content_list)):  # Check lengths of items
                raise AttributeError('The second attribute of table() has to be a list of lists or dictionaries, '
                                     'which are of the same length, as the first attribute!')
            if all(map(lambda x: isinstance(x, list), content_list)):  # Process list of lists
                for row in content_list:
                    # Check, if row has the required length
                    if len(row) != len(self._head):
                        raise AttributeError('At least one element of "content_list" has the wrong length!')
                    else:
                        # Convert list of uniform lists to list of uniform dictionaries
                        self.add(dict(zip(self._head, row)))
            elif all(map(lambda x: isinstance(x, dict), content_list)):  # Process list of dictionaries
                self._table = []
                for row_dict in content_list:  # type: Dict[str, Any]
                    self.add(row_dict)
            else:  # Something is very wrong, if we get here
                raise AttributeError('The attribute "content_list", if not None, has to be '
                                     'a list of ONLY lists or '
                                     'a list of ONLY dictionaries!')
        else:
            self._table = []

    def __repr__(self):
        """
        Magic method, called when Table object is printed

        :return: Object description
        :rtype: str
        """
        return 'Table object with ' + str(len(self._table)) + ' entries.'

    def __str__(self):
        """
        Magic method, called by str()

        :return: Content of Table object in table-like format
        :rtype: str
        """
        output = ['\033[1m' + str(self._head) + '\033[0m']
        for table_row in self._table:
            row_list = []
            for col_name in self._head:
                row_list.append(table_row[col_name])
            output.append(str(row_list))
        return '\n'.join(output)

    def __getitem__(self, col: str) -> List[Any]:
        """
        Magic method, called by []-accessor

        :param col: Column name, has to be in "_head".
        :type col: str
        :return: Content of column, which name is matching "col".
        :rtype: list
        """
        if col in self._head:
            output = []  # type: List[Any]
            for table_row in self._table:
                output.append(table_row[col])
            return output
        else:
            raise AttributeError('table has no column named "' + str(col) + '"')

    def __len__(self) -> int:
        """
        Magic method, called by len()

        :return: Number of rows (entries) in table
        :rtype: int
        """
        return len(self._table)

    # Magic method to initialize iterator.
    def __iter__(self):
        self._index = 0
        self._row = None
        return self

    # Magic method to increment iterator.
    def __next__(self):
        if self._index > len(self._table) - 1:
            del self._index
            del self._row
            raise StopIteration
        else:
            self._row = self._table[self._index]
            output = self._row
            self._index = self._index + 1
            return output

    @property
    def head(self):
        """Provides iterable over columns."""
        out = []
        for col_name in self._head:
            out.append(col_name)
        return out

    def add(self, row: Dict[str, Any]):
        """
        Method to add row to Table object.

        :param row: Row to be added to table. May have content beyond the needed keys.
        :type row: dict
        """
        if not isinstance(row, dict):  # Check Type
            raise TypeError('table.add() expects a dictionary as argument')
        if len(row) < len(self._head):  # Check length
            raise ValueError('The argument of add_row has to be a dictionary with the length of at least '
                             + str(len(self._head)))
        new_row = {}
        for col in self._head:  # Add only keys defined in head to the table
            try:
                new_row[col] = row[col]
            except KeyError:  # If row misses a key
                raise AttributeError('The dictionary given to table.add() misses at least one key, '
                                     'defined in the first attribute of table()!')
        self._table.append(new_row)

    def remove_column(self, col_name: str):
        """
        Method to remove column

        :param col_name: Name of the column to be removed.
        :type col_name: str
        """
        if not isinstance(col_name, str):
            raise TypeError('Attribute "col_name" of method "remove_column" has to be of type string.')
        if col_name not in self._head:
            raise AttributeError('Attribute "col_name" of method "remove_column" is not a column in Table object.')
        self._head.remove(col_name)
        for entry in self._table:
            entry.pop(col_name, None)

    def query(self, pattern: Union[Dict[str, Any], str]) -> Union[List[Dict[str, Any]], None]:
        """
        Method to search the table for either all rows with a field matching pattern string or all rows where the
        content of column, defined in pattern dictionary, matches the value, associated in dictionary.

        :param pattern: Search pattern, either as string, searched in all columns,
        or dictionaries, defining column and object to be searched as key/value pairs.
        :type pattern: str or dict
        :return: List of dictionaries, holding the result of the query, or None, if nothing was found
        """
        result = []
        if not isinstance(pattern, (dict, str)):
            raise TypeError('table.query() takes a dict or a string as argument!')
        elif isinstance(pattern, dict):
            result += self._table
            for pattern_key in pattern:
                if pattern_key in self._head:
                    result = list(filter(lambda x: x[pattern_key] == pattern[pattern_key], result))
                else:
                    raise ValueError(pattern_key + ' is not a column in table!')
        elif isinstance(pattern, str):
            for head_key in self._head:
                result += list(filter(lambda x: x[head_key] == pattern, self._table))
        if not result:
            return None
        else:
            return result


class PVDb(Table):
    """Main container for data from all sources, child of class table"""

    def __init__(self, logging: Any = sys.stderr):
        """
        :param logging: Object with 'write()' method, i.e. Logger or sys.stderr
        :type logging: object
        """
        super().__init__(['devicePath', 'pvName', 'recordType', 'autosave', 'doku', 'fields'], None)
        self.aliases = {}
        if not callable(getattr(logging, 'write')):
            raise AttributeError('Attribute "logging" of PVDb object has to be an object with a "write" method!')
        else:
            self.log = logging

    def __getitem__(self, pv_id: str) -> dict:
        """
        Magic method to access dataset (row) with the field 'devicePath' matching pv_id
        :param pv_id: String to search for in field 'devicePath'
        :return: Dictionary holding the whole dataset
        """
        if not isinstance(pv_id, str):  # Check Type
            raise TypeError('Attribute of PVDb[] has to be string.')
        query_result = super().query({'devicePath': pv_id})  # Find Entry
        if len(query_result) == 0:  # Check existence
            self.log.write(AsciiFormat.error
                           + 'PV with device path '
                           + pv_id + ' does not exist in PVDb')
        elif len(query_result) == 1:  # Usual case
            index = self._table.index(query_result[0])
            return self._table[index]
        elif len(query_result) >= 1:  # Check Multiple Entries
            self.log.write(AsciiFormat.error +
                           'Multiple PVs with device path '
                           + pv_id
                           + ' found in PVDb! PVDb might be corrupted!')
        else:  # For unforeseen cases
            raise RuntimeError('Something has gone wrong!')

    def _expand(self, in_str):
        """
        Recursive method to replace strings, placed between "*{" and "}"
        :param in_str: String to be expanded
        :return: Expanded string
        """
        if not isinstance(in_str, str):
            raise TypeError('Attribute "in_str" of "_expand"-method has to be of type string')
        else:
            pos_open = in_str.find("*{")
            if pos_open != -1:
                pos_close = in_str.find("}", pos_open + 1)
                if pos_close == -1:
                    return in_str
            else:
                return in_str
            try:
                if pos_close - pos_open > 1:  # Check for empty curly brackets
                    macro = self.aliases[in_str[pos_open + 2:pos_close]]
                else:
                    self.log.write(AsciiFormat.warning + 'Empty Macro in string "' + in_str + '" will be ignored!')
                    macro = ''
            except KeyError:
                self.log.write(AsciiFormat.warning
                               + 'Macro '
                               + in_str[pos_open:pos_close + 1]
                               + ' not defined, and will be ignored!')
                macro = ''
            out = self._expand(in_str[:pos_open] + macro + in_str[pos_close + 1:])
        return out

    def recordtypes(self) -> List[str]:
        """
        Method to get a list of all different record types, present in database.
        :return: List with record types
        """
        return list(set(super().__getitem__('recordType')))  # list(set(list)) construct to eliminate duplicates

    def records_of_type(self, record_type: str) -> Table:
        """
        Method to extract sub Table with PVs of same record type
        :param record_type: Record type to extract
        :return: Table holding only records of given record type
        """
        out_content = self.query({'recordType': record_type})
        return Table(['devicePath', 'pvName', 'autosave', 'doku', 'fields'], content_list=out_content)


class XmlSource(Table):
    """
    Class to handle data from xml files, generated with <ChimeraTK-server>-xmlGenerator.
    """

    def __init__(self,
                 xml_filepath: str,
                 namespace: str,
                 logger: Any = sys.stderr,
                 aliases: Optional[Dict[str, str]] = None):
        """
        Constructor of XmlSource object

        :param xml_filepath: Filename or path to xml file to be parsed
        :type xml_filepath: str, path-like
        :param namespace: Namespace used in xml file
        :type namespace: str
        :param logger: Object with "write" method, i.e. sys.stderr or Logging-class object
        :type logger: object
        :param aliases: Aliases for expansion
        :type aliases: dict
        """
        if not os.path.isfile(xml_filepath):
            raise AttributeError(str(xml_filepath) + ' is not an existing file!')
        if not callable(getattr(logger, 'write')):
            raise AttributeError('Attribute "logger" of class XmlSource has to have a callable method "write(str)"')
        self.logger = logger
        super().__init__(['Alias',
                          'VariablePath',
                          'VariableName',
                          'value_type',
                          'numberOfElements',
                          'direction',
                          'unit',
                          'description'])
        # Indexing "variables" in xml file
        if isinstance(namespace, str):
            self.ns_dict = {'namespace_prefix': namespace}
        else:
            raise TypeError('The attribute "namespace" of class XmlSource has to be a string!')
        self._index = []
        if aliases is None:
            self.aliases = {}
        else:
            self.aliases = aliases
        self.file = os.path.abspath(xml_filepath)
        self._tree = xmlEleTree.parse(self.file)
        self._root = self._tree.getroot()
        self.application = self._root.get('name')
        self._make_index(self._root)
        # Extract Information from source xml
        for variable in self._index:
            var_path = variable['var_path']
            var_name = variable['var_name']
            var_data = {'value_type': None,
                        'unit': '',
                        'description': '',
                        'direction': None,
                        'numberOfElements': None}
            try:  # To catch SkipLoop
                for val_key in var_data:
                    try:
                        var_data[val_key] = variable['xml_address'].find('namespace_prefix:' +
                                                                         val_key, self.ns_dict).text
                    except AttributeError:
                        self.logger.write(AsciiFormat.error +
                                          'Attribute "value_type" not found in ' +
                                          AsciiFormat.bold(var_path + var_name) +
                                          '!')
                        if val_key in ['direction', 'numberOfElements']:
                            raise SkipLoop
            except SkipLoop:
                self.logger.write('Variable will be ignored')
                continue
            if len(self.aliases) > 0:
                try:
                    var_alias = self.aliases[var_path]
                except KeyError:
                    self.logger.write('No alias found for ' + str(var_path) + '! Using full xml path instead!')
                    var_alias = var_path[:-1]  # Cut the last slash
            else:
                var_alias = var_path
            # Assembling content
            self.__add({
                'Alias': var_alias,
                'VariablePath': var_path,
                'VariableName': var_name,
                'value_type': var_data['value_type'],
                'direction': var_data['direction'],
                'unit': var_data['unit'],
                'description': var_data['description'],
                'numberOfElements': int(var_data['numberOfElements'])
            })

    # Magic method for "object[string]" accessor. Returns the row with Alias = string.
    def __getitem__(self, search_str: str) -> Dict[str, Any]:
        """
        Magic method for []-accessor.

        :param search_str: String to be found in 'Alias'-column
        :type search_str: str
        :return: Entry, whose 'Alias' column in matching 'search_str'
        :rtype: dict
        """
        if not isinstance(search_str, str):  # Check Type
            raise TypeError('Attribute of XmlSource[] has to be string.')
        query_result = super().query({'Alias': search_str})  # Find Entry
        if len(query_result) == 0:  # Check existence
            self.logger.write(AsciiFormat.error
                              + 'Entry with Alias '
                              + search_str
                              + ' does not exist in XmlSource')
        elif len(query_result) == 1:  # Usual case
            index = self._table.index(query_result[0])
            return self._table[index]
        elif len(query_result) >= 1:  # Check Multiple Entries
            self.logger.write(AsciiFormat.error +
                              'Multiple PVs with ID '
                              + search_str
                              + ' found in PVDb! PVDb might be corrupted!')
        else:  # For unforeseen cases
            raise RuntimeError('Something has gone wrong!')

    def _make_index(self, xml_node: Any, pv_path: str = ''):
        """
        Recursive method to iterate through the xml tree and isolate the 'variables'
        while maintaining the path in order to generate an index.

        :param xml_node: xml handle to start the recursion
        :type xml_node: object
        :param pv_path: Path to the node, from which the function is called.
        :type pv_path: str
        """
        for v in xml_node.findall('namespace_prefix' + ':variable', self.ns_dict):
            self._index.append({'xml_address': v, 'var_path': pv_path, 'var_name': v.get('name')})
        for d in xml_node.findall('namespace_prefix' + ':directory', self.ns_dict):
            self._make_index(d, pv_path=pv_path + d.get('name') + '/')
        return  # Break recursion, if no more directories found

    def __add(self, row: Dict[str, Any]):  # To bend add method of parent class to hidden method
        super().add(row)

    def add(self, row):  # To hide add method of parent class
        raise AttributeError("'XmlSource' object has no attribute 'add'")

    def update_aliases(self):
        """
        Updates the "Alias" field in self._table with content of self.aliases.

        """
        for entry in self._table:
            if entry['Alias'] in self.aliases:
                entry['Alias'] = self.aliases[entry['Alias']]

    def make_aliases(self):
        """
        Returns dictionary with aliases, generated from the xmlPath by omitting the seperator '/' and, after
        abbreviating the individual elements, setting the result in camel case, i.e.:
        XML/Path/element/1/ -> XmlPathElem1
        Needs the function "abbreviate" to be present in scope.
        """
        out = {}
        for path in list(set(super().__getitem__('VariablePath'))):  # list(set(list)) to remove duplicates
            words = path.split('/')
            alias_string = ''
            for word in words:
                short_word = abbreviate(word.casefold())
                alias_string += short_word.capitalize()
            out[path] = alias_string
        self.aliases.update(out)
        self.update_aliases()


class EpicsCfg:
    """
    Class to read, process and generate EPICS config files
    """

    def __init__(self, cfg_file_path: str, logger: Any = sys.stderr):
        """
        Class constructor
        :param cfg_file_path: String holding valid path to file or directory
        :param logger: Object with callable function "write"
        """
        if not callable(getattr(logger, 'write')):
            raise AttributeError('Attribute "logger" of class XmlSource has to have a callable method "write(str)"')
        self.logger = logger
        if not isinstance(cfg_file_path, str):
            raise TypeError('Argument "cfg_path" has to be a string, preferably holding the path to a file!')
        self._cfg_abspath = os.path.abspath(cfg_file_path)
        self._cfg_dir, self._cfg_file = os.path.split(self._cfg_abspath)
        if not os.path.isdir(self._cfg_dir):
            raise AttributeError(self._cfg_dir + ' is not a valid path to an existing directory!')
        self.file_path = cfg_file_path
        self._sources = {}

    def load_source(self, source_path: str, source_label: str, source_type: str = 'xml', **kwargs):
        if not isinstance(source_path, str):
            raise TypeError('Argument "source_path" of function "load_source" has to be of type string')
        if not isinstance(source_type, str):
            raise TypeError('Argument "source_type" of function "load_source" has to be of type string')
        source_types = ['xml']
        if source_type not in source_types:
            raise AttributeError('Argument "source_type" of function "load_source" has to be one of the following: ' +
                                 ', '.join(source_types))
        if source_type == 'xml':
            self._sources[source_label] = XmlSource(source_path, kwargs['namespace'], logger=self.logger)

    def generate_config_file(self, source_label: str, macro: Optional[str] = None, macro_length: Optional[int] = 0):
        """
        Method to generate simple config xml file as a blank.

        :param source_label: Label of the xml-source, to access it in self.sources-dictionary
        :type source_label: str
        :param macro: Macro to be added to all PVs
        :type macro: str, None
        :param macro_length: Length to be reserved in pv name for macro
        :type macro_length: int
        """
        if not isinstance(self._sources[source_label], XmlSource):
            raise TypeError('source_label has to refer to XmlSource object in self._sources member of class EpicsCfg!')
        xml_source = self._sources[source_label]  # type: XmlSource
        gen_log = Logging(source_label + 'CfgGen.log')  # Generate seperate log file
        gen_log.write('Start of config file generation.')
        if macro is not None:
            if not isinstance(macro, str):
                raise TypeError('Argument "macro" has to be a string!')
            if not isinstance(macro_length, int):
                raise TypeError('Argument "macro_length" has to be an integer!')
        # Prompt if existing file should be overwritten, and end function, if not
        if os.path.isfile(self._cfg_abspath) and not \
                input('File ' + self._cfg_abspath + ' exists! Overwrite? (y/n):').lower() in ['y', 'yes']:
            gen_log.write('Ending config file generation to not overwrite existing file!')
            return
        # Dictionary to convert c types into EPICS counterparts
        pv_type_conversion = {'int64': 'INT64',
                              'uint64': 'UINT64',
                              'int32': 'LONG',
                              'uint32': 'ULONG',
                              'int16': 'SHORT',
                              'uint16': 'USHORT',
                              'int8': 'CHAR',
                              'uint8': 'UCHAR',
                              'double': 'DOUBLE',
                              'float': 'FLOAT',
                              'string': 'STRING'}
        # Dictionary to convert "direction" to EPICS IN/OUT
        pv_direction_determination = {'control_system_to_application': 'OUT',
                                      'control_system_to_application_with_return': 'OUT',
                                      'application_to_control_system': 'INP',
                                      'application_to_control_system_with_return': 'INP'}
        # Dictionary to determine record type
        pv_type_determination = {'INPFalseINT64': 'int64in',
                                 'INPFalseUINT64': 'int64in',
                                 'INPFalseFLOAT': 'ai',
                                 'INPFalseDOUBLE': 'ai',
                                 'INPFalseSHORT': 'longin',
                                 'INPFalseUSHORT': 'longin',
                                 'INPFalseLONG': 'longin',
                                 'INPFalseULONG': 'longin',
                                 'INPFalseCHAR': 'longin',
                                 'INPFalseUCHAR': 'longin',
                                 'INPFalseSTRING': 'lsi',
                                 'INPTrueINT64': 'aai',
                                 'INPTrueUINT64': 'aai',
                                 'INPTrueFLOAT': 'aai',
                                 'INPTrueDOUBLE': 'aai',
                                 'INPTrueSHORT': 'aai',
                                 'INPTrueUSHORT': 'aai',
                                 'INPTrueLONG': 'aai',
                                 'INPTrueULONG': 'aai',
                                 'INPTrueCHAR': 'aai',
                                 'INPTrueUCHAR': 'aai',
                                 'INPTrueSTRING': 'aai',
                                 'OUTFalseINT64': 'int64out',
                                 'OUTFalseUINT64': 'int64out',
                                 'OUTFalseFLOAT': 'ao',
                                 'OUTFalseDOUBLE': 'ao',
                                 'OUTFalseSHORT': 'longout',
                                 'OUTFalseUSHORT': 'longout',
                                 'OUTFalseLONG': 'longout',
                                 'OUTFalseULONG': 'longout',
                                 'OUTFalseCHAR': 'longout',
                                 'OUTFalseUCHAR': 'longout',
                                 'OUTFalseSTRING': 'lso',
                                 'OUTTrueINT64': 'aao',
                                 'OUTTrueUINT64': 'aao',
                                 'OUTTrueFLOAT': 'aao',
                                 'OUTTrueDOUBLE': 'aao',
                                 'OUTTrueSHORT': 'aao',
                                 'OUTTrueUSHORT': 'aao',
                                 'OUTTrueLONG': 'aao',
                                 'OUTTrueULONG': 'aao',
                                 'OUTTrueCHAR': 'aao',
                                 'OUTTrueUCHAR': 'aao',
                                 'OUTTrueSTRING': 'aao'}
        # Dictionary to determine autosave based on record type
        pv_autosave_determination = {'int64out': 'true',
                                     'int64in': 'false',
                                     'ao': 'true',
                                     'ai': 'false',
                                     'longout': 'true',
                                     'longin': 'false',
                                     'aao': 'false',
                                     'aai': 'false',
                                     'lso': 'true',
                                     'lsi': 'false'}
        # Determine value of SCAN field, depending on record type
        pv_scan_determination = {'int64out': '.5 seconds',
                                 'int64in': 'Passive',
                                 'ao': '.5 seconds',
                                 'ai': 'Passive',
                                 'longout': '.5 seconds',
                                 'longin': 'Passive',
                                 'aao': '.5 seconds',
                                 'aai': 'Passive',
                                 'lso': '.5 seconds',
                                 'lsi': 'Passive'}
        pvs = Table(['pvName', 'devicePath', 'recordType', 'autosave', 'fields'])
        xml_source.make_aliases()
        gen_log.write('Compile data from xml.')
        for entry in xml_source:  # Build database
            pv_recordtype = pv_type_determination[pv_direction_determination[entry['direction']]
                                                  + str(entry['numberOfElements'] > 1)
                                                  + pv_type_conversion[entry['value_type']]]
            pv_fields_determination = {
                'int64out': {'SCAN': pv_scan_determination[pv_recordtype],
                             'OUT': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                             'EGU': ':unit'},
                'int64in': {'SCAN': pv_scan_determination[pv_recordtype],
                            'INP': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                            'EGU': ':unit'},
                'ao': {'SCAN': pv_scan_determination[pv_recordtype],
                       'OUT': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                       'EGU': ':unit'},
                'ai': {'SCAN': pv_scan_determination[pv_recordtype],
                       'INP': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                       'EGU': ':unit'},
                'longout': {'SCAN': pv_scan_determination[pv_recordtype],
                            'OUT': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                            'EGU': ':unit'},
                'longin': {'SCAN': pv_scan_determination[pv_recordtype],
                           'INP': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                           'EGU': ':unit'},
                'lso': {'SCAN': pv_scan_determination[pv_recordtype],
                        'OUT': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName']},
                'lsi': {'SCAN': pv_scan_determination[pv_recordtype],
                        'INP': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName']},
                'aao': {'SCAN': pv_scan_determination[pv_recordtype],
                        'OUT': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                        'EGU': ':unit',
                        'FTVL': ':value_type',
                        'NELM': ':numberOfElements'},
                'aai': {'SCAN': pv_scan_determination[pv_recordtype],
                        'INP': '@$(APP) ' + '*{' + entry['Alias'] + '}' + entry['VariableName'],
                        'EGU': ':unit',
                        'FTVL': ':value_type',
                        'NELM': ':numberOfElements'}
            }
            if macro is not None:
                pv_macro = '$(' + macro + ')'
            else:
                pv_macro = ''
            pv_name = entry['Alias'] + '/' + entry['VariableName']
            if len(pv_name) > 39 - macro_length:
                gen_log.write('PV name "' + pv_macro + pv_name + '" is too long.')
            pvs.add({'devicePath': xml_source.application + '.*{' + entry['Alias'] + '}' + entry['VariableName'],
                     'pvName': pv_macro + pv_name,
                     'recordType': pv_recordtype,
                     'autosave': pv_autosave_determination[pv_recordtype],
                     'fields': pv_fields_determination[pv_recordtype]})
        cfg_xmlns = 'https://github.com/ChimeraTK/ControlSystemAdapter-EPICS-IOC-Adapter'
        cfg_xml_root = xmlEleTree.Element('EPICSdb', xmlns=cfg_xmlns, application=xml_source.application)
        cfg_xml_source = xmlEleTree.SubElement(cfg_xml_root, 'sourcefile',
                                               type='xml-variables',
                                               path=xml_source.file,
                                               namespace=xml_source.ns_dict['namespace_prefix'],
                                               label=xml_source.application)
        for xml_path in xml_source.aliases:
            xmlEleTree.SubElement(cfg_xml_source, 'alias', varLabel=xml_source.aliases[xml_path], xmlPath=xml_path)
        if xml_source.file[-4:] == '.xml':
            db_path = xml_source.file[:-4] + '.db'
        else:
            db_path = xml_source.application + '.db'
        # Generate db file definition
        cfg_xml_output_db = xmlEleTree.SubElement(cfg_xml_root, 'outputfile',
                                                  type='db',
                                                  path=db_path,
                                                  macroReserve=str(macro_length))
        # Set file generic 'fields'
        xmlEleTree.SubElement(cfg_xml_output_db, 'field', type='DTYP', value='ChimeraTK')
        for rec_type in list(set(pvs['recordType'])):
            cfg_xml_recordtype = xmlEleTree.SubElement(cfg_xml_output_db, 'recordgroup',
                                                       type=rec_type,
                                                       autosave=pv_autosave_determination[rec_type])
            # Extract records of same type
            records = Table(['devicePath', 'pvName', 'autosave', 'fields'],
                            content_list=pvs.query({'recordType': rec_type}))
            # Find default fields
            record_fields = Table(list(records['fields'][0].keys()), records['fields'])  # type: Table
            for field_name in record_fields.head:
                field_val = record_fields[field_name]  # type: List[Any]
                field_val_elements = list(set(field_val))
                if len(field_val_elements) == 1:
                    xmlEleTree.SubElement(cfg_xml_recordtype, 'field', type=field_name, value=field_val_elements[0])
                    for record in records:
                        record['fields'].pop(field_name, None)
            for record in records:
                cfg_xml_record = xmlEleTree.SubElement(cfg_xml_recordtype, 'record',
                                                       pvName=record['pvName'],
                                                       source=record['devicePath'])
                fields = record['fields']
                for field in fields:
                    xmlEleTree.SubElement(cfg_xml_record, 'field', type=field, value=fields[field])
        xml_list = []
        xml_list_item = ''
        for element in xmlEleTree.tostringlist(cfg_xml_root, encoding='unicode', method='xml'):
            xml_list_item += element
            if xml_list_item[-1] == '>':
                xml_list.append(xml_list_item)
                xml_list_item = ''
        indent_level = 0
        xml_str = '<?xml version="1.0" encoding="UTF-8"?>\n'
        indent = '    '
        for tag in xml_list:
            if tag[:2] == '</':
                indent_level -= 1
            if indent_level < 0:
                indent_level = 0
            xml_str += indent_level * indent + tag + '\n'
            if tag[-2:] != '/>' and tag[:2] != '</':
                indent_level += 1
        with open(self.file_path, 'w', encoding='utf-8') as file:
            file.write(xml_str)

    def load_cfg_file(self):
        """
        Process existing config file!
        """


def expand_alias(in_string, alias_dict):
    """Function to expand aliases"""

    pos_open = in_string.find("{")
    if pos_open != -1:
        pos_close = in_string.find("}", pos_open + 1)
        if pos_close == -1:
            return in_string
    else:
        return in_string
    macro = alias_dict[in_string[pos_open + 1:pos_close]]
    temp = in_string[:pos_open] + macro + in_string[pos_close + 1:]
    out = expand_alias(temp, alias_dict)
    return out


def find_x_dir(xml_root, ns_prefix, ns_dict, xpath, logger: Logging = sys.stderr):
    """
    Returns address of directory-node, described in xPath.
    """
    nodes = [xml_root]
    for xml_node in xpath.split('/'):
        temp = nodes[-1].findall(ns_prefix + ":directory[@name='" + xml_node + "']", ns_dict)
        if len(temp) == 0:
            raise XmlNodeError(xpath, 'findXDir: "directory" node does not exist!')
        elif len(temp) > 1:
            logger.write(
                AsciiFormat.warning +
                'Multiple directory-nodes named ' +
                xml_node +
                ' found. First one will be used!\n')
        else:
            nodes.append(temp[0])
    return nodes[-1]


def xml_tag_description(xml_node):
    """Returns string describing content of node"""
    node_type = xml_node.tag.split('}')[-1]
    if node_type == 'outputfile':
        output = AsciiFormat.bold('outputfile') + ' for ' + AsciiFormat.bold(node.get('path'))
    elif node_type == 'recordgroup':
        output = AsciiFormat.bold('recordgroup') + ' of type ' + AsciiFormat.bold(node.get('type'))
    elif node_type == 'pv':
        output = AsciiFormat.bold('pv') + ' named ' + AsciiFormat.bold(node.get('pvName'))
    else:
        output = AsciiFormat.bold('unknown')
    return output


def get_macro(xml_node, ns_prefix, ns_dict, logger: Logging = sys.stderr):
    """
    Returns a struct holding length and placeholder as defined in the FIRST "macro" tag
    under the xml.etree Element, given in "node"
    "nsDict" is a dict holding "nsPrefix" and namespace(s) as key:value pairs.
    """
    output = Struct()  # type: Struct
    output.node = xml_node.find(ns_prefix + ':macro', ns_dict)
    whoami = xml_tag_description(xml_node)  # For error messages
    if output.node is None:  # There is no 'macro' child in this xml element
        output.length = 0
        output.placeholder = ''
    else:
        temp_length = output.node.get('length')
        temp_ph = output.node.get('placeholder')
        if temp_length is None:  # "macro"-child exists, but has no "length"-attribute
            logger.write(AsciiFormat.error +
                         'No "length" was defined for macro in' +
                         whoami +
                         '! PV name(s) will have no macro.')
            output.length = 0
            output.placeholder = ''
        else:
            output.length = int(temp_length)
        if temp_ph is None:  # "macro"-child exists, but has no "placeholder"-attribute
            logger.write(AsciiFormat.error +
                         'No "placeholder" was defined for macro in' +
                         whoami +
                         '! PV name(s) will have no macro.')
            output.length = 0
            output.placeholder = ''
        else:  # Everything is as expected
            output.placeholder = str(output.node.get('placeholder'))
    return output


def get_autosave(xml_node, ns_prefix, ns_dict, logger: Logging = sys.stderr):
    """
    Returns a boolean as defined in the FIRST "autosave" tag under the xml.etree Element, given in "node".
    "nsDict" is a dict holding "nsPrefix" and namespace(s) as key:value pairs.
    """
    output = Struct()  # type: Struct
    output.node = xml_node.find(ns_prefix + ':autosave', ns_dict)
    whoami = xml_tag_description(xml_node)  # For error messages
    if output.node is None:  # There is no 'autosave' child in this xml element
        output.active = None
    elif output.node.get('isActive') is None:  # autosave child exists, but has no "isActive"-attribute
        logger.write(AsciiFormat.error +
                     'No "isActive" was defined for autosave in' +
                     whoami +
                     '! PV will not be added to autosave.')
        output.active = None
    elif output.node.get('isActive').lower() not in ['true', 'false']:  # "isActive"-attribute holds unrecognized value
        logger.write(AsciiFormat.error +
                     '"isActive", defined for autosave in' +
                     whoami +
                     ' has to be "true" or "false" (not case-sensitive), but is not! '
                     'PV will not be added to autosave.')
        output.active = None
    else:  # Everything is as expected
        output.active = {'true': True, 'false': False}[output.node.get('isActive').lower()]
    return output.active


def get_fields(xml_node, ns_prefix, ns_dict, logger: Logging = sys.stderr):
    """
    Returns a dictionary holding all "field" tags type:value attributes under the xml.etree Element,
     given in "xml_node" as key:value pairs.
    "ns-dict" is a dict holding "ns-prefix" and namespace(s) as key:value pairs.
    :rtype: dict
    """
    output = dict()
    field_nodes = xml_node.findall(ns_prefix + ':field', ns_dict)
    whoami = xml_tag_description(xml_node)  # For error messages
    for field in field_nodes:
        field_type = field.get('type')
        field_value = field.get('value')
        if field_type is None:
            if field_value is None:
                logger.write(AsciiFormat.error +
                             'No "value" attribute was defined for a "field" child in '
                             + whoami
                             + '! "field" element will be ignored!')
            logger.write(AsciiFormat.error +
                         'No "type" attribute was defined for a "field" child in '
                         + whoami
                         + '! "field" element will be ignored!')
        elif field_value is None:
            logger.write(AsciiFormat.error +
                         'No "value" attribute was defined for a "field" child in '
                         + whoami
                         + '! "field" element will be ignored!')
        else:
            output[field_type] = field_value  # Fields of the same type overwrite!
    return output


CLAP = argparse.ArgumentParser(
    description='Generates EPICS PV database for every \'PV\' defined in ChimeraTK-xml file to EPICS database file.')
CLAP.add_argument('-c',
                  help='Path to configuration file. Defaults to "mapConfig.xml"',
                  metavar='path')
CLAP.add_argument('-v',
                  help='Activates verbosity.',
                  action='store_true')
CLAP.add_argument('-l',
                  help='Define path to logfile. Defaults to dbGen.log in CWD.',
                  metavar='path',
                  default='dbGen.log')
# Parse Command Line Arguments
CLA = CLAP.parse_args()

# Handle CLI arguments
# Handle default case
if CLA.c is None:
    inifile_path = os.getcwd()
    inifile_name = 'mapConfig.xml'
else:
    inifile_path, inifile_name = os.path.split(os.path.abspath(CLA.c))
    # Handle input of filename only
    if inifile_path is None:
        inifile_path = os.getcwd()
# Handle invalid/non-existing paths
if not os.path.isdir(inifile_path):
    sys.exit(AsciiFormat.error + 'Path ' + inifile_path + ' does not exist.')
elif not os.path.isfile(os.path.join(inifile_path, inifile_name)):
    sys.exit(AsciiFormat.error + 'File ' + inifile_name + ' does not exist.')

# initiate logging
log = Logging(CLA.l)

# Parse config file os.path.join(inifilePath, inifileName)
if CLA.v:
    log.write("Reading: " + os.path.join(inifile_path, inifile_name))
cfgTree = xmlEleTree.parse(os.path.join(inifile_path, inifile_name))
cfgRoot = cfgTree.getroot()

# Define namespace
configNS = {'EPICSmap': 'https://github.com/ChimeraTK/ControlSystemAdapter-EPICS-IOC-Adapter'}
# Get a list of all sourcefile entries
sourcefiles = cfgRoot.findall("EPICSmap:sourcefile", configNS)

# Check existence of sourcefile element(s)
if len(sourcefiles) == 0:
    log.write(AsciiFormat.warning + 'No source files are defined!\n')
else:
    if CLA.v:
        sourcelist = []
        for i in sourcefiles:
            sourcelist.append(os.path.abspath(i.get("path")))
        print('Found ' + str(len(sourcefiles)) + ' sources:\n- ' + '\n- '.join(sourcelist) + '\n')
    source = dict()
    alias = dict()
    for sfile in sourcefiles:
        # Check if sourcefile exists
        if not os.path.isfile(sfile.get("path")):
            log.write(
                AsciiFormat.warning + 'File "'
                + os.path.abspath(sfile.get('path'))
                + '" does not exist!')
        # Parse source file according to type
        sourceTag = sfile.get("label")
        if sfile.get("type") == "xml-variables":
            # parse aliases
            for item in sfile.findall('EPICSmap:alias', configNS):
                alias[item.get('xmlPath')] = item.get('varLabel')
            # parse xmlfile
            cfg = EpicsCfg('test_cfg.xml', logger=log)
            cfg.load_source('/home/countzero/ChimeraTK/build/Watchdog/WatchdogServer.xml',
                            'watchdog',
                            namespace='https://github.com/ChimeraTK/ApplicationCore')
            cfg.generate_config_file('watchdog', macro='P', macro_length=5)
        else:
            sys.stderr.write(
                AsciiFormat.warning + 'Source file type '
                + sfile.get("type")
                + ' is unknown. Source file '
                + sfile.get("path")
                + ' labeled '
                + sfile.get("label")
                + ' will be ignored!\n')

# Get a list of all outputfile entries
outputFiles = cfgRoot.findall("EPICSmap:outputfile", configNS)
outputList = Table(['type', 'path', 'handle'])
for i in outputFiles:
    outputFile = {'path': os.path.abspath(i.get('path')), 'type': i.get('type'), 'handle': i}
    outputList.add(outputFile)
if CLA.v:
    print(str(len(outputList)) + ' output files are defined:\n' + str(outputList) + '\n')

for outFile in outputList:
    macro_rgroup = Struct()
    macro_rgroup.length = 0
    macro_rgroup.placeholder = ""
    autosave_rgroup = None
    fields_rgroup = dict()
    if outFile['type'] == 'db':
        node = outFile['handle']
        # process attributes for the whole file
        macro_file = get_macro(node, 'EPICSmap', configNS, logger=log)
        autosave_file = {None: False, False: False, True: True}[get_autosave(node, 'EPICSmap', configNS, logger=log)]
        fields_file = get_fields(node, 'EPICSmap', configNS, logger=log)
        # process recordgroups
        rgroupList = node.findall('EPICSmap' + ':recordgroup', configNS)
        for rgroupNode in rgroupList:
            macro_temp = get_macro(rgroupNode, 'EPICSmap', configNS, logger=log)
            if macro_temp.node is not None:
                macro_rgroup = macro_temp
            else:
                macro_rgroup = macro_file
            autosave_temp = get_autosave(rgroupNode, 'EPICSmap', configNS, logger=log)
            if autosave_temp is not None:
                autosave_rgroup = autosave_temp
            else:
                autosave_rgroup = autosave_file
            fields_rgroup = fields_file
            fields_rgroup.update(get_fields(rgroupNode, 'EPICSmap', configNS, logger=log))

        print(str(macro_rgroup.length) +
              '\t' +
              macro_rgroup.placeholder +
              '\n' +
              str(autosave_rgroup) +
              '\n' +
              str(fields_rgroup) +
              '\n')
